# Language name (default: Bambara)
LANGUAGE_NAME=Bambara

# Directory for caching translation results (default: instruction_generation_cache)
TRANSLATION_CACHE=instruction_generation_cache

# Maximum number of retries for API calls (default: 5)
MAX_RETRIES=5

# Delay between retries in seconds (default: 5)
RETRY_DELAY=5

# Timeout for batch processing in seconds (default: 1200)
BATCH_TIMEOUT=1200

# Interval for saving checkpoints (default: 10)
CHECKPOINT_INTERVAL=10

# Size of each batch for processing (default: 20)
BATCH_SIZE=20

# General API timeout in seconds (default: 600.0)
TIMEOUT=600.0

# Maximum number of workers (default: 20)
MAX_WORKERS=20

# Number of concurrent batches (default: 20)
CONCURRENT_BATCHES=20

# Rate limiter semaphore value (default: 100)
RATE_LIMITER=100

# AI model name (default: gemini-2.5-pro because of the fact that it's natively a reasoning model)
MODEL_NAME=gemini-2.5-pro

# Base URL for the API (default: https://generativelanguage.googleapis.com/v1beta/openai/)
BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/

# Maximum tokens for API responses (default: 2 Million tokens)
MAX_TOKENS=2000000

# Temperature for model generation (default: 0.1) lower values make output more deterministic
TEMPERATURE=0.1

# Top-p value for model generation (default: 0.9)
TOP_P=0.9

# API key (required)
API_KEY=your_api_key_here

# Path to glossary file (default: resources/glossary.json)
GLOSSARY_FILE=resources/glossary.json

# Path to grammar rules file (default: resources/grammar_rule.json)
GRAMMAR_RULE_FILE=resources/grammar_rule.json

# Path to CONLLU file (default: resources/bm_crb-ud-test.conllu)
CONLLU_FILE=resources/bm_crb-ud-test.conllu

# Folder containing dataset JSONL files (default: datasets)
DATASETS_FOLDER=datasets